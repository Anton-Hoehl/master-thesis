{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time \n",
    "import gc\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.models.segmentation\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision import transforms as transforms3\n",
    "from torchvision.utils import draw_bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability and GPU information\n",
    "print('Is Cuda available: ', str(torch.cuda.is_available()), \n",
    "      '\\nAvailable GPUs: ', str(torch.cuda.device_count()), \n",
    "      '\\nList of GPUs: \\n', [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images change path if necessar to wherever image_date_data_.pkl is \n",
    "pkl_path = '/home/adm_gpu/projects/masterthesis/code/advertisements/image_date_data_.pkl'\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    og_l_images = pickle.load(f)\n",
    "\n",
    "final_frame = pd.DataFrame(og_l_images[:], columns=['journal', 'date', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = final_frame.image.tolist()\n",
    "print('Loaded Images: ', str(len(raw_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (600, 800)  # Adjust dimensions\n",
    "\n",
    "# As most of the images are scans we need to resize them for the model to guarantee uniform dimensions\n",
    "def resize_and_pad(image, target_size):\n",
    "\n",
    "    resized_image = image.resize(target_size)\n",
    "\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
    "    \n",
    "    new_image.paste(resized_image, ((target_size[0] - resized_image.size[0]) // 2, (target_size[1] - resized_image.size[1]) // 2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "# Resize images\n",
    "resized_images = [resize_and_pad(img, target_size) for img in raw_images]\n",
    "\n",
    "# verify amount of images\n",
    "print(\"Resized images: \", len(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model setup\n",
    "weights = MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "transforms = weights.transforms()\n",
    "\n",
    "model = maskrcnn_resnet50_fpn_v2(weights=weights, progress=False).cuda() # important to leverage cuda\n",
    "model = torch.nn.DataParallel(model, device_ids=[0]) # does not work with multi gpu \n",
    "model = model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure run\n",
    "start_time = time.time()\n",
    "\n",
    "# Process images in batches\n",
    "segmented_images = []\n",
    "\n",
    "# categories from model weights metadata\n",
    "categories_list = weights.meta['categories']\n",
    "\n",
    "# transform images in batch to cuda due to vram limit\n",
    "for i in range(0, len(resized_images), 2 ): \n",
    "    selection = resized_images[i:i + 2]\n",
    "    \n",
    "    transformed = [transforms3.functional.pil_to_tensor(element).to('cuda') for element in selection]\n",
    "    images = [transforms(element) for element in transformed]\n",
    "\n",
    "    print(len(images))\n",
    "\n",
    "    batch_tensor = torch.stack(images).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_tensor)\n",
    "\n",
    "    print(\"Images annotated: \" + str(len(outputs)))\n",
    "\n",
    "    for output in outputs:\n",
    "\n",
    "        labels_tensor = output['labels']\n",
    "        scores_tensor = output['scores']\n",
    "\n",
    "        filtered_labels = labels_tensor[scores_tensor > 0.65]\n",
    "        segmented_images.append([categories_list[label.item()] for label in filtered_labels])\n",
    "print(len(segmented_images))\n",
    "\n",
    "final_frame['information'] = segmented_images\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print('Elapsed Time: ', elapsed_time, '\\n', 30 * '=', '\\n', segmented_images[0:26:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change if necessary\n",
    "path = '/home/adm_gpu/projects/masterthesis/code/main/dataframe.pkl'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(final_frame, file)\n",
    "\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(f\"Time taken to save final_frame: {time_taken:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verfify write operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frame\n",
    "path = '/home/adm_gpu/projects/masterthesis/code/main/dataframe.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    dataframe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "# check version \n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre checks\n",
    "print(torch.cuda.is_available(), '\\n',\n",
    "torch.cuda.device_count(), '\\n',\n",
    "torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and initiate model\n",
    "processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "# set processor to the same dimensions as the model\n",
    "processor.image_processor.size = {\"height\": 224, \"width\": 224}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared data \n",
    "\n",
    "path = '/home/adm_gpu/projects/masterthesis/code/main/dataframe.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    pictures = pickle.load(f)\n",
    "\n",
    "# check if load was successful \n",
    "pictures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify image format \n",
    "l_images = list(pictures['image'])\n",
    "l_images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[im.resize((224, 224)) for im in l_images[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['text', 'background', 'person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialze multiple pandsa series to store information \n",
    "\n",
    "prompt_dict = {\n",
    "    'text': pd.Series(dtype='float'),\n",
    "    'logo': pd.Series(dtype='float'),\n",
    "    'background': pd.Series(dtype='float'),\n",
    "    'person': pd.Series(dtype='float'),\n",
    "    'landscape': pd.Series(dtype='float')\n",
    "}\n",
    "\n",
    "\n",
    "# resize to model spec, this will distort DIN A4 pages as they are not square \n",
    "for image in [im.resize((224, 224)) for im in l_images]:\n",
    "  start = time.time()\n",
    "  for i in range(1,len(prompts)):\n",
    "    tolist = prompts[:i+1]\n",
    "\n",
    "    inputs = processor(text=tolist, images=[image] * len(tolist), padding=\"max_length\", return_tensors=\"pt\")\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "    preds = nn.functional.interpolate(\n",
    "        outputs.logits.unsqueeze(1),\n",
    "        size=(image.size[1], image.size[0]),\n",
    "        mode=\"bilinear\"\n",
    "    )\n",
    "  \n",
    "  \n",
    "\n",
    "  for k in range(len(prompts)):\n",
    "\n",
    "    iterres = torch.sigmoid(preds[k][0])\n",
    "\n",
    "    thresh = 0.1\n",
    "\n",
    "    positives = (iterres > thresh).sum().item()\n",
    "    total_elements = iterres.numel()\n",
    "\n",
    "    perc = round(positives / total_elements, 4)\n",
    "\n",
    "    prompt_dict[prompts[k]] = pd.concat([prompt_dict[prompts[k]], pd.Series(perc)], ignore_index=True)\n",
    "    #print(prompts[k], perc)\n",
    "\n",
    "  end = time.time()\n",
    "  diff = end - start\n",
    "  print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/adm_gpu/projects/masterthesis/code/main/prompt_dict.pkl'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(prompt_dict, file)\n",
    "\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dict['background']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/adm_gpu/projects/masterthesis/code/main/annotated_frame.pkl'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(pd.concat([pictures, pd.DataFrame(prompt_dict).drop(['logo', 'landscape'], axis = 1)], axis = 1), file)\n",
    "\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
